---
title: "Brief lessons from using LLM APIs in production"
date: "2023-08-20"
excerpt: "Practical lessons from six months of building and operating LLM APIs in production at Looppanel."
category: "AI"
tags: ["llm", "production", "api", "chatgpt", "machine-learning"]
published: true
---

## Introduction

One day, a nuanced post about production LLM deployment will emerge—better than all previous ones. Until then, here are practical lessons from six months of building and operating LLM APIs in production.

## Outline

1. Chat isn't always the answer
2. You don't need to know everything
   - a. It doesn't hurt to know a bit more than you need
3. Tinker
4. Open source is your friend but APIs are not your enemy
5. Demos will take a weekend, production will keep you up on weekends

## Lesson 1: Chat Isn't Always the Answer

Not every product needs "ChatGPT for X." While chat interfaces offer flexibility, they can overwhelm users seeking focused help for professional tasks. Users often need structured guidance rather than infinite possibilities.

The author references their work at Looppanel, where they provide interview notes tied to evidence rather than conversational transcripts. This approach prevents hallucination by prioritizing factual accuracy and truthfulness.

## Lesson 2: You Don't Need to Know Everything

The pace of AI advancement is overwhelming. Rather than drowning in constant updates from Twitter and Arxiv, focus on understanding what you specifically need for your project.

### Lesson 2a: A Little Extra Knowledge Helps

While deep expertise in RAG and vector databases isn't necessary, rudimentary understanding of embeddings can prove valuable. Skimming relevant voices and newsletters occasionally provides useful context without demanding constant engagement.

## Lesson 3: Tinker

Hands-on experimentation with models—whether through ChatGPT conversations or porting models like Llama in C—accelerates learning. Discoveries like "think step by step" prompting emerge through direct tinkering.

## Lesson 4: Open Source vs. APIs

Open source tools are valuable, but APIs may better suit strict timelines or early-stage development. After validating your use-case and methodology, transitioning to open-source fine-tuning becomes more feasible.

## Lesson 5: Demos vs. Production

Building impressive demos differs fundamentally from production deployment. Production requires extensive testing, monitoring, guardrails, and cache strategies. Multiple failure points—cost, latency, model drift—demand careful attention.

## Lesson 6 (Bonus): Have Fun and Be Responsible

Enjoy working with transformative technology while maintaining ethical responsibility. Encourage curiosity and help others understand LLMs responsibly.

## Conclusion

The AI landscape shifts rapidly. The technology will continue evolving unpredictably. Preparation and engagement with these developments matter significantly.
